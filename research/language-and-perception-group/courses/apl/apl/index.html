<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 2.32.13"/><title data-react-helmet="true"></title><link data-react-helmet="true" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&amp;display=swap" rel="stylesheet"/><link data-react-helmet="true" rel="stylesheet" type="text/css" media="all" href="/css/bootstrap.min.css"/><link data-react-helmet="true" rel="stylesheet" type="text/css" media="all" href="/css/theme.css"/><link data-react-helmet="true" rel="stylesheet" type="text/css" media="all" href="/css/style.css"/><link data-react-helmet="true" rel="stylesheet" type="text/css" media="all" href="/css/menu.css"/><meta data-react-helmet="true" name="google-site-verification" content="aLbLg9i2oE98fQuvzFSYrW6xSSAyrCk7cZxLPzDiz4s"/><script data-react-helmet="true" type="text/javascript" src="/js/jquery-3.5.1.min.js"></script><script data-react-helmet="true" type="text/javascript" src="/js/bootstrap.min.js"></script><script data-react-helmet="true" type="text/javascript" src="/js/base.js"></script><link as="script" rel="preload" href="/webpack-runtime-df4e8c76addaafc8837b.js"/><link as="script" rel="preload" href="/framework-073c72e9d2e4c2490fcd.js"/><link as="script" rel="preload" href="/app-9846c3f7f4b3f0350ee6.js"/><link as="script" rel="preload" href="/commons-5dfeb980da566c46321b.js"/><link as="script" rel="preload" href="/component---src-templates-markdown-template-js-cf19b8e806f90d375072.js"/><link as="fetch" rel="preload" href="/page-data/research/language-and-perception-group/courses/apl/apl/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3875542623.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body data-spy="scroll" data-target="#toc"><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="container-fluid"><div class="row"><div class="container"><header class="jumbotron subhead mb-0" id="overview"><div class="row"><div id="clasp-header-logo" class="align-self-center col-md-3 col-12"><img src="/img/clasp.png" href="https://clasp.gu.se" alt="The Centre for Linguistic Theory and Studies in Probability"/></div><div class="align-self-center col-md-6 col-12"><div style="font-size:1.5rem">The Centre for Linguistic Theory and Studies in Probability</div></div><div class="col-md-3 col-12"><img id="gu-header-logo" src="/img/gu-logo.png" href="gu.se" alt="University of Gothenburh"/></div></div></header><nav class="navbar navbar-light navbar-expand-lg mainmenu border rounded-lg"><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav" style="width:100%"><li class="col p-0 text-center"><a href="/">Home</a></li><li class="col p-0 text-center dropdown"><a class="dropdown-toggle" aria-expanded="false">News</a><ul class="dropdown-menu"><li class="col p-0 text-center"><a href="/news">News</a></li><li class="col p-0 text-center"><a href="/recruitment">Recruitment</a></li></ul></li><li class="col p-0 text-center dropdown"><a class="dropdown-toggle" aria-expanded="false">Events</a><ul class="dropdown-menu"><li class="col p-0 text-center"><a href="/event?type=calendar">Calendar</a></li><li class="col p-0 text-center"><a href="/event?type=seminars&amp;page=1">Seminars</a></li><li class="col p-0 text-center"><a href="/event?type=conference">Conferences &amp; Workshops</a></li><li class="col p-0 text-center"><a href="https://sites.google.com/view/reinact2021/home">ReInAct</a></li></ul></li><li class="col p-0 text-center dropdown"><a class="dropdown-toggle" aria-expanded="false">Projects</a><ul class="dropdown-menu"><li class="col p-0 text-center"><a href="http://www.christinehowes.com/research/drips">Dialogical Reasoning in Patients with Schizophrenia (DRiPS)</a></li><li class="col p-0 text-center"><a href="http://www.christinehowes.com/research/incred">Incremental Reasoning in Dialogue (IncReD)</a></li><li class="col p-0 text-center"><a href="https://wasp-hs.org/projects/gothenburg-research-initiative-for-politically-emergent-systems-gripes/">Gothenburg research initiative for politically emergent systems (GRIPES)</a></li></ul></li><li class="col p-0 text-center"><a href="/phd-courses">Courses</a></li><li class="col p-0 text-center dropdown"><a class="dropdown-toggle" aria-expanded="false">Research Groups</a><ul class="dropdown-menu"><li class="col p-0 text-center dropdown"><a class="dropdown-toggle" aria-expanded="false">Language and Perception</a><ul class="dropdown-menu"><li class="col p-0 text-center"><a href="/research/language-and-perception-group/">About</a></li><li class="col p-0 text-center"><a href="/research/language-and-perception-group/meetings/">Reading group</a></li><li class="col p-0 text-center dropdown"><a class="dropdown-toggle" aria-expanded="false">Courses</a><ul class="dropdown-menu"><li class="col p-0 text-center"><a href="/research/language-and-perception-group/courses/rom/rom/">Representations of Meaning</a></li><li class="col p-0 text-center"><a href="/research/language-and-perception-group/courses/apl/apl/">Language, Action, and Perception</a></li><li class="col p-0 text-center"><a href="/research/language-and-perception-group/courses/csoc/csoc/">Sociolinguistics and Bilingualism for NLP</a></li><li class="col p-0 text-center"><a href="/research/language-and-perception-group/courses/ml-vl/ml-vl/">ML Methods for Vision and Language</a></li></ul></li></ul></li><li class="col p-0 text-center dropdown"><a class="dropdown-toggle" aria-expanded="false">Dialogue</a><ul class="dropdown-menu"><li class="col p-0 text-center"><a href="/research/dialogue-group/">About</a></li><li class="col p-0 text-center"><a href="/research/dialogue-group/meetings/">Reading group</a></li></ul></li><li class="col p-0 text-center"><a href="/research/machine-learning-group/">Machine Learning</a></li><li class="col p-0 text-center"><a href="/research/type-theory-group/">Type Theory</a></li></ul></li><li class="col p-0 text-center"><a href="/people">People</a></li><li class="col p-0 text-center"><a href="/contact">Contact</a></li></ul></div></nav></div></div><div class="row"><div class="container"><div style="padding-top:20px;padding-bottom:20px" class="row"><div class="col"><div class="blog-post-container"><div class="blog-post"><h1>Language, Action, and Perception (APL)</h1><h2></h2><div class="blog-post-content"><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/fc9c71d76312d207d482a2c94d3edb8e/d2602/IMG_5943.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAUBAgT/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAv/aAAwDAQACEAMQAAAB0VUzUMxSH//EABsQAAEEAwAAAAAAAAAAAAAAAAABAgMREBNB/9oACAEBAAEFAqjUdpQuM5j/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwGI/8QAFREBAQAAAAAAAAAAAAAAAAAAABL/2gAIAQIBAT8Btb//xAAaEAACAgMAAAAAAAAAAAAAAAAAEAEyAiFh/9oACAEBAAY/AtZwWLLi/8QAGhAAAwADAQAAAAAAAAAAAAAAAAERITFxgf/aAAgBAQABPyGSiZu74qJi19MsZlFP/9oADAMBAAIAAwAAABBH3//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EJS//8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARQf/aAAgBAgEBPxAT21f/xAAbEAEBAQEBAAMAAAAAAAAAAAABEQAxUUFxgf/aAAgBAQABPxAuH6Xmgrpzu+8QZ34DcIkX9ymylRe6HlT3f//Z'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="IMG 5943" title="IMG 5943" src="/static/fc9c71d76312d207d482a2c94d3edb8e/4b190/IMG_5943.jpg" srcset="/static/fc9c71d76312d207d482a2c94d3edb8e/e07e9/IMG_5943.jpg 200w,
/static/fc9c71d76312d207d482a2c94d3edb8e/066f9/IMG_5943.jpg 400w,
/static/fc9c71d76312d207d482a2c94d3edb8e/4b190/IMG_5943.jpg 800w,
/static/fc9c71d76312d207d482a2c94d3edb8e/e5166/IMG_5943.jpg 1200w,
/static/fc9c71d76312d207d482a2c94d3edb8e/b17f8/IMG_5943.jpg 1600w,
/static/fc9c71d76312d207d482a2c94d3edb8e/d2602/IMG_5943.jpg 4032w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy">
  </a>
    </span>
<p>APL HT18 and onwards, Language, Action, and Perception, 7.5 HEC, Spr√•k, handling och perception, 7,5hp, part of <a href="https://medarbetarportalen.gu.se/digitalAssets/1656/1656982_asp-fd-datalingvistik-2016-eng.pdf">Doctoral Degree in Computational
Linguistics</a>.</p>
<p>This is PhD course that explores computational modelling of language and vision in particular in relation to situated dialogue agents and image classification. There is a parallel course at the masters level which this course may partially overlap with: LT2308 ESLP: Embodied and Situated Language Processing or LT2318: Artificial Intelligence: Cognitive Systems.</p>
<p>The course gives a survey of theory and practical computational implementations of how natural language interacts with the physical world through action and perception. We will look at topics such as semantic theories and computational approaches to modelling natural language, action and perception (grounding), situated dialogue systems, integrated robotic systems, grounding of language in action and perception, generation and interpretation of scene descriptions from images and videos, spatial cognition, and others.</p>
<p>As the course studies how humans structure and interact with the physical world and express it in language, it bridges into the domains of cognitive science, computer vision, robotics and therefore more broadly belongs to the field of cognitive artificial intelligence. Typical applications of computational models of language, action, and perception are image search and retrieval on the web, navigation systems that provide more natural, human-like instructions, and personal robots and situated conversational agents that interact with us in our home environment through language.</p>
<p>The learning outcomes of the course are based on covering 3 topics: (i) the relation between language and perception in human interaction, (ii) how language and perception is modelled with formal and computational models and methods and how these are integrated with different applications, and (iii) how research in the field is communicated scientifically.</p>
<p>Course prerequisites:</p>
<ul>
<li>General admission requirements for a doctoral degree in Computational Linguistics or equivalent.</li>
</ul>
<p>In order to follow the course, the participants should at least have experience with one or several of the following fields at masters level:</p>
<ul>
<li>Formal semantics and pragmatics</li>
<li>Natural language processing</li>
<li>Computational semantics</li>
<li>Machine learning</li>
<li>Robotics</li>
<li>or equivalent skills and knowledge.</li>
</ul>
<p>Course syllabus</p>
<ul>
<li><a href="/252d2215499653c932c9eaafd8ad4487/Language,%20Action%20and%20Perception.pdf">In Swedish</a></li>
</ul>
<h2>Requirements</h2>
<p>Please read <a href="/ee40cbbcc8ef5b736efb415fdcc56c44/requirements.md">this document</a> and talk to Simon.</p>
<h2>Lecturers</h2>
<ul>
<li><a href="https://www.gu.se/en/about/find-staff/simondobnik">Simon Dobnik</a> (course organiser), office hours: by appointment</li>
</ul>
<h2>Course literature</h2>
<p>For a list of suggested readings please see <a href="https://gu-clasp.github.io/language-and-perception/meetings/">here</a>. Individual readings will be suggested for each meeting.</p>
<h2>Schedule and course materials</h2>
<ul>
<li>
<p><strong>Contextual referrring expressions</strong> </p>
<ul>
<li>2020-06-12, Zoom</li>
<li>Pezzelle, S., &#x26; Fern√°ndez, R. (2019). <a href="https://arxiv.org/pdf/1908.10285.pdf">Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual Contexts.</a> arXiv preprint arXiv:1908.10285. (recommended by Staffan) 2020-06-12 </li>
<li>Staffan (presenter), Tewodros, Maryam, Mehdi, Simon, and Robin</li>
</ul>
</li>
<li>
<p><strong>Visual question answering and background knowledge</strong></p>
<ul>
<li>2020-05-29, Zoom</li>
<li>Talk: M√≠riam S√°nchez-Alc√≥n: <a href="https://gubox.app.box.com/s/djn8w0k2qlmkgbdsr8yk0dsz22r1fjsj">The significance of applying attention to Visual Question Answering</a></li>
<li>Wu, J., &#x26; Mooney, R. J. (2018). <a href="http://arxiv.org/abs/1809.02805">Faithful Multimodal Explanation for Visual Question Answering</a> [cs.CL], 2020. (recommended by Simon) 2020-05-29</li>
<li>Nikolai (presenter), Miriam (presenter), Tewodros, Robin, Staffan, Simon</li>
</ul>
</li>
<li>
<p><strong>Word complexity and concreteness, requirements for social and embodied NLP</strong></p>
<ul>
<li>2020-04-30, Zoom</li>
<li>Talk: David Alfter: <a href="https://gubox.box.com/shared/static/nuyn4p02bcj8pok1lmd9huf54wfmt8an.pdf">Visual features in textual complexity classification: a case study on pictograms</a></li>
<li>Y. Bisk, A. Holtzman, J. Thomason, J. Andreas, Y. Bengio, J. Chai, M. Lapata, A. Lazaridou, J. May, A. Nisnevich, N. Pinto, and J. Turian. <a href="https://arxiv.org/abs/2004.10151">Experience grounds language.</a> arXiv, arXiv:2004.10151 [cs.CL], 2020. 2020-04-30</li>
<li>Robin, Staffan, Mehdi, Nikolai, Bill, Vlad, Tewodros, Maryam, David, Elena, Simon</li>
</ul>
</li>
<li>
<p><strong>Generating image descriptions, natural language generation</strong></p>
<ul>
<li>2020-04-17, Zoom</li>
<li>J. Krause, J. Johnson, R. Krishna, and L. Fei-Fei. <a href="https://arxiv.org/pdf/1611.06607.pdf">A hierarchical approach for generating descriptive image paragraphs.</a> In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3337‚Äì3345, July 21‚Äì26 2017.</li>
<li>Nikolai (presenter), Mehdi, Robin, Vlad, Bill, Aram, Maryam, and Simon</li>
</ul>
</li>
<li>
<p><strong>Generating image descriptions and pragmatics</strong></p>
<ul>
<li>2020-03-20, Zoom</li>
<li>Cohn-Gordon, R., Goodman, N., &#x26; Potts, C. (2018). <a href="http://arxiv.org/abs/1804.05417">Pragmatically Informative Image Captioning with Character-Level Inference.</a></li>
<li>Nikolai (presenter), Mehdi, Robin, Vlad, Bill, Tewodros and Simon (check)</li>
</ul>
</li>
<li>
<p><strong>Spatial representations, representation learning, interpretability</strong></p>
<ul>
<li>2019-02-08 10-12 Dicksonsgatan 4</li>
<li>G. Collell, L. V. Gool, and M. Moens. <a href="http://arxiv.org/abs/1711.06821">Acquiring common sense spatial knowledge through implicit spatial templates.</a> arXiv, arXiv:1711.06821 [cs.AI]:1‚Äì8, 2017.</li>
<li>Mehdi (presenter), Felix, Vlad, Robin, Staffan, Simon</li>
</ul>
</li>
<li>
<p><strong>Language and action</strong></p>
<ul>
<li>2019-03-08 10-12 Dicksonsgatan 4</li>
<li>Forestier S, Oudeyer P-Y. (2017) <a href="http://sforestier.com/node/32">A Unified Model of Speech and Tool Use Early Development.</a> Proceedings of the 39th Annual Meeting of the Cognitive Science Society. </li>
<li>Sylvie (presenter), Felix, Mehdi, Bill, Robin, Stergios, Simon</li>
</ul>
</li>
</ul>
<p>You can find  an earlier version of this webpage <a href="/74682c28ab17c7a660752b885fe6b6ed/archived.zip">here</a>.</p></div></div></div></div></div></div></div><div class="row"><footer id="footer" style="width:100%"><div class="row"><div class="col-12 col-md-4 col"><div class="footer-header-type-style">Contact Information</div><p><b>Office Hours: </b>Monday-Friday (9.00am - 5.00pm)</p><p><b>Phone: </b>Phone +46 31-786 0000</p><p><b>E-mail: </b><a href="mailto:susanna.myyry@gu.se">susanna.myyry@gu.se</a></p></div><div class="col-12 col-md-4 col"><div class="footer-header-type-style">Quick Links</div><p><a href="/news">News</a></p><p><a href="https://gu-clasp.github.io/recruitment/" target="_blank">Recruitment</a></p><p><a href="https://clasp.gu.se" target="_blank">CLASP GU page</a></p><p><a href="https://www.gu.se/en" target="_blank">University of Gothenburg</a></p></div><div class="col-12 col-md-4 col"><div class="footer-header-type-style">Address</div><p>University of Gothenburg<br/>Department of Philosophy, Linguistics and Theory of Science <br/>CLASP - Centre for Linguistic Theory and Studies in Probability<br/>P.o. Box 200<br/>se-405 30 GOTHENBURG<br/>SWEDEN</p><a href="https://goo.gl/maps/kga7QHae7wfKfKNfA" target="_blank">Show Map</a></div></div></footer></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/research/language-and-perception-group/courses/apl/apl/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-d4801ee0a32a09229c1f.js"],"app":["/app-9846c3f7f4b3f0350ee6.js"],"component---src-pages-404-js":["/component---src-pages-404-js-71fbab4e444732050f7b.js"],"component---src-pages-contact-js":["/component---src-pages-contact-js-9db7986dbfafb9b9d453.js"],"component---src-pages-event-js":["/component---src-pages-event-js-715dc6f3143a95ac532b.js"],"component---src-pages-index-js":["/component---src-pages-index-js-5e902811d507af65f1cd.js"],"component---src-pages-news-js":["/component---src-pages-news-js-9229238085b13af41dc6.js"],"component---src-pages-people-js":["/component---src-pages-people-js-bc8259094e482874865c.js"],"component---src-pages-phd-courses-js":["/component---src-pages-phd-courses-js-81f7033338a2bd9cde60.js"],"component---src-pages-publication-js":["/component---src-pages-publication-js-a58ec3b16ee6b914a4c6.js"],"component---src-pages-recruitment-js":["/component---src-pages-recruitment-js-29c48941d44a87be9d00.js"],"component---src-pages-research-js":["/component---src-pages-research-js-1595c11c291aec7d21cf.js"],"component---src-templates-conference-template-js":["/component---src-templates-conference-template-js-d41a88b05dee04ed0951.js"],"component---src-templates-course-template-js":["/component---src-templates-course-template-js-d2fb3999c5e1aa7f7831.js"],"component---src-templates-markdown-template-js":["/component---src-templates-markdown-template-js-cf19b8e806f90d375072.js"],"component---src-templates-news-template-js":["/component---src-templates-news-template-js-bf42bbb2384d2e457e7f.js"],"component---src-templates-recruitments-template-js":["/component---src-templates-recruitments-template-js-48ab7d6105d2168d0192.js"],"component---src-templates-seminar-template-js":["/component---src-templates-seminar-template-js-82f16061dc7480995c1f.js"],"component---src-templates-staff-template-js":["/component---src-templates-staff-template-js-08c0ff82e19158435a87.js"],"component---src-templates-workshop-template-js":["/component---src-templates-workshop-template-js-9ba2d3565da19d5d813d.js"]};/*]]>*/</script><script src="/polyfill-d4801ee0a32a09229c1f.js" nomodule=""></script><script src="/component---src-templates-markdown-template-js-cf19b8e806f90d375072.js" async=""></script><script src="/commons-5dfeb980da566c46321b.js" async=""></script><script src="/app-9846c3f7f4b3f0350ee6.js" async=""></script><script src="/framework-073c72e9d2e4c2490fcd.js" async=""></script><script src="/webpack-runtime-df4e8c76addaafc8837b.js" async=""></script></body></html>