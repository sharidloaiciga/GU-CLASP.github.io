{"componentChunkName":"component---src-templates-markdown-template-js","path":"/research/language-and-perception-group/courses/ml-vl/ml-vl/","result":{"data":{"markdownRemark":{"html":"<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/efb132d7ad23f3a0cf3c8b8908f2e678/72e01/tree.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAME/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAU06jQgH/8QAGRAAAgMBAAAAAAAAAAAAAAAAAREAAiES/9oACAEBAAEFAjbOkAbIjcbn/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAES/9oACAEDAQE/AZGX/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAES/9oACAECAQE/AbWn/8QAFxABAAMAAAAAAAAAAAAAAAAAABEgMf/aAAgBAQAGPwKkNf/EABoQAQEAAwEBAAAAAAAAAAAAAAEAESExUYH/2gAIAQEAAT8h6Vy3SzsrUz1YU/i283//2gAMAwEAAgADAAAAENQP/8QAGBEAAgMAAAAAAAAAAAAAAAAAABEBIVH/2gAIAQMBAT8Qidi4f//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAgEBPxCjb//EABsQAQACAwEBAAAAAAAAAAAAAAEAESExQXFR/9oACAEBAAE/ECCqm7+RGy75cBJC8lQBiGxXOS4C3aUxfkXkIa1P/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"tree\" title=\"tree\" src=\"/static/efb132d7ad23f3a0cf3c8b8908f2e678/4b190/tree.jpg\" srcset=\"/static/efb132d7ad23f3a0cf3c8b8908f2e678/e07e9/tree.jpg 200w,\n/static/efb132d7ad23f3a0cf3c8b8908f2e678/066f9/tree.jpg 400w,\n/static/efb132d7ad23f3a0cf3c8b8908f2e678/4b190/tree.jpg 800w,\n/static/efb132d7ad23f3a0cf3c8b8908f2e678/72e01/tree.jpg 1024w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n<p>ML-V&#x26;L HT18 and onwards, Machine Leanring for Vision and Language, 7.5 HEC, Maskininlärningsmetoder för datorseende och språkteknologi, 7,5hp, part of <a href=\"/60258ce07b1a37468f83125a132441c9/Degree%20of%20Doctor%20in%20Computational%20Linguistics.pdf\">Doctoral Degree in Computational\nLinguistics</a>.</p>\n<p>The course focuses on machine learning/deep learning models and techniques such as Recurrent Neural Networks (RNNs), Long-Short Term Memory Networks (LSTMs), Convolutional Neural Networks (ConvNets), Neural Auto-Encoders, Memory Networks, and others applied to computational modeling of natural language and images, and other sensory information. </p>\n<p>Theoretically, it examines how machine learning approaches address topics such as multi-modal grounded representations of meaning, representing and resolving semantic ambiguity, attention and salience, perception and dialogue interaction, natural language interpretation, natural language generation, natural language reasoning and inference, and collection of perceptual and linguistic data. </p>\n<p>Practically, the course overviews contemporary computer vision and natural language processing tasks such as generating image and video descriptions, visual question answering, image retrieval using text queries, aligning images and text in large data collections, image generation from textual descriptions, and others.</p>\n<p>Course prerequisites:</p>\n<ul>\n<li>General admission requirements for a doctoral degree in Computational Linguistics or equivalent.</li>\n</ul>\n<p> In order to follow the course, the participants should at least have experience with one or several of the following fields at masters level:</p>\n<p> Students are expected to have a knowledge of (i) practical programming, for example in Python, (ii) natural language processing, and (iii) machine/deep learning, or equivalent.</p>\n<ul>\n<li>Practical programming, for example in Python</li>\n<li>Natural language processing</li>\n<li>Machine/deep learning</li>\n<li>or equivalent skills and knowledge.</li>\n</ul>\n<p>Course syllabus</p>\n<ul>\n<li><a href=\"/2fa647f2b6d18ffe822064c111cec63e/course-plan-ml-vl.pdf\">In English</a></li>\n</ul>\n<h2>Requirements</h2>\n<p>Please read <a href=\"/ee40cbbcc8ef5b736efb415fdcc56c44/requirements.md\">this document</a> and talk to Simon.</p>\n<h2>Lecturers</h2>\n<ul>\n<li><a href=\"https://www.gu.se/en/about/find-staff/simondobnik\">Simon Dobnik</a> (course organiser), office hours: by appointment</li>\n</ul>\n<h2>Course literature</h2>\n<p>For a list of suggested readings please see <a href=\"https://gu-clasp.github.io/language-and-perception/meetings/\">here</a>. Individual readings will be suggested for each meeting.</p>\n<h2>Schedule and course materials</h2>\n<ul>\n<li>Topics will appear here</li>\n</ul>","frontmatter":{"title":"Machine Learning Methods For Vision and Language (ML-V&L)","date":null},"fields":{"slug":"/research/language-and-perception-group/courses/ml-vl/ml-vl/"}}},"pageContext":{"slug":"/research/language-and-perception-group/courses/ml-vl/ml-vl/"}},"staticQueryHashes":["3875542623"]}